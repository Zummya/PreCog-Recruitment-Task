{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14585086,"sourceType":"datasetVersion","datasetId":9316866}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#gpt attempt\nimport pandas as pd\nimport networkx as nx\nfrom collections import defaultdict\nimport numpy as np\n\nfile_path = '/kaggle/input/train-txt/train.txt'\ndf = pd.read_csv(file_path, sep=r'\\s+', names=['head','relation','tail'])\n\npeople = pd.Index(df['head']).union(df['tail'])\nprint(\"Train triples:\", len(df), \"| people:\", len(people), \"| relations:\", df['relation'].nunique())\n\n# --- parent->child backbone T ---\nPARENT_REL = {'fatherOf','motherOf'}\nCHILD_REL  = {'sonOf','daughterOf'}\n\nT = nx.DiGraph()\nT.add_nodes_from(people)\n\nfor h,r,t in df[['head','relation','tail']].itertuples(index=False):\n    if r in PARENT_REL:\n        T.add_edge(h,t)\n    elif r in CHILD_REL:\n        T.add_edge(t,h)\n\nprint(\"Backbone edges (parent->child):\", T.number_of_edges())\n\n# Generation estimate (component-wise)\ngen = {}\nfor comp in nx.weakly_connected_components(T):\n    sub = T.subgraph(comp)\n    roots = [n for n in sub.nodes() if sub.in_degree(n)==0]\n    for r in roots: gen[r]=0\n    for node in nx.topological_sort(sub):\n        if node not in gen:\n            parents = list(sub.predecessors(node))\n            gen[node] = (max(gen[p] for p in parents) + 1) if parents else 0\n\n# Family id = backbone weak component id\ncomps = list(nx.weakly_connected_components(T))\nfamily_id = {}\nfor i, comp in enumerate(comps):\n    for n in comp:\n        family_id[n] = i\n\nprint(\"Families (components):\", len(comps),\n      \"| size range:\", (min(len(c) for c in comps), max(len(c) for c in comps)))\n\n# --- G_all: all relations as undirected weighted edges ---\nG_all = nx.Graph()\nG_all.add_nodes_from(people)\n\nfor h,r,t in df[['head','relation','tail']].itertuples(index=False):\n    a,b = (h,t) if h < t else (t,h)\n    if G_all.has_edge(a,b):\n        G_all[a][b]['weight'] += 1\n        G_all[a][b]['relations'].add(r)\n    else:\n        G_all.add_edge(a,b, weight=1, relations={r})\n\nprint(\"G_all edges:\", G_all.number_of_edges(),\n      \"| mean weight:\", np.mean([d['weight'] for _,_,d in G_all.edges(data=True)]))\n\n# --- Build siblings and couples from T (needs 2-parent children) ---\nparents2 = {c: tuple(sorted(T.predecessors(c))) for c in T.nodes()}\nchild2 = {c:p for c,p in parents2.items() if len(p)==2}\n\ncouple_children = defaultdict(set)\nfor c,(p1,p2) in child2.items():\n    couple_children[(p1,p2)].add(c)\n\n# full-sibs: share both parents\nsib_pairs = set()\nfor (p1,p2), kids in couple_children.items():\n    kids = sorted(kids)\n    for i in range(len(kids)):\n        for j in range(i+1,len(kids)):\n            sib_pairs.add((kids[i], kids[j]))\n\nprint(\"Couples w/children:\", len(couple_children),\n      \"| children w/2 parents:\", len(child2),\n      \"| sibling pairs (derived):\", len(sib_pairs))\n\n# --- G_close: close-kin graph (parent-child + siblings + spouse) ---\nG_close = nx.Graph()\nG_close.add_nodes_from(people)\n\ndef add_w(u,v,w,etype):\n    a,b = (u,v) if u < v else (v,u)\n    if G_close.has_edge(a,b):\n        G_close[a][b]['weight'] += w\n        G_close[a][b]['types'].add(etype)\n    else:\n        G_close.add_edge(a,b, weight=w, types={etype})\n\n# parent-child edges (strong)\nfor p,c in T.edges():\n    add_w(p,c, w=3, etype='parent')\n\n# sibling edges (strong)\nfor a,b in sib_pairs:\n    add_w(a,b, w=2, etype='sibling')\n\n# spouse edges inferred by co-parenting (moderate)\nfor (p1,p2) in couple_children.keys():\n    add_w(p1,p2, w=2, etype='spouse')\n\nprint(\"G_close edges:\", G_close.number_of_edges())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-03T08:15:37.847460Z","iopub.execute_input":"2026-02-03T08:15:37.848106Z","iopub.status.idle":"2026-02-03T08:15:38.015227Z","shell.execute_reply.started":"2026-02-03T08:15:37.848070Z","shell.execute_reply":"2026-02-03T08:15:38.014366Z"}},"outputs":[{"name":"stdout","text":"Train triples: 13821 | people: 14634 | relations: 28\nBackbone edges (parent->child): 1642\nFamilies (components): 50 | size range: (26, 27)\nG_all edges: 7480 | mean weight: 1.8477272727272727\nCouples w/children: 445 | children w/2 parents: 821 | sibling pairs (derived): 603\nG_close edges: 2690\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from networkx.algorithms.community import modularity\n\ndef run_louvain(G):\n    try:\n        return nx.community.louvain_communities(G, weight='weight', seed=42)\n    except Exception as e:\n        print(\"Louvain not available in this NetworkX:\", e)\n        raise\n\ndef run_lpa(G):\n    # weighted async label propagation if available\n    try:\n        comms = list(nx.community.asyn_lpa_communities(G, weight='weight', seed=42))\n        return comms\n    except TypeError:\n        comms = list(nx.community.asyn_lpa_communities(G, seed=42))\n        return comms\n\ndef summarize_partition(G, comms, name):\n    sizes = sorted([len(c) for c in comms], reverse=True)\n    Q = modularity(G, comms, weight='weight')\n    intra = 0\n    for u,v,d in G.edges(data=True):\n        w = d.get('weight',1)\n        # membership test via map\n    print(f\"\\n== {name} ==\")\n    print(\"communities:\", len(comms))\n    print(\"size stats (top5):\", sizes[:5], \"| min/median/max:\", (min(sizes), int(np.median(sizes)), max(sizes)))\n    print(\"modularity Q:\", round(Q,4))\n    return Q, sizes\n\ndef comm_map(comms):\n    m = {}\n    for i,c in enumerate(comms):\n        for n in c:\n            m[n]=i\n    return m\n\n# Run\nparts = {}\nfor Gname, G in [('G_all', G_all), ('G_close', G_close)]:\n    L = run_louvain(G); parts[(Gname,'louvain')] = L\n    P = run_lpa(G);     parts[(Gname,'lpa')]     = P\n\n    summarize_partition(G, L, f\"{Gname} / Louvain\")\n    summarize_partition(G, P, f\"{Gname} / LabelProp\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T08:15:38.016981Z","iopub.execute_input":"2026-02-03T08:15:38.017256Z","iopub.status.idle":"2026-02-03T08:15:38.450994Z","shell.execute_reply.started":"2026-02-03T08:15:38.017230Z","shell.execute_reply":"2026-02-03T08:15:38.449810Z"}},"outputs":[{"name":"stdout","text":"\n== G_all / Louvain ==\ncommunities: 50\nsize stats (top5): [27, 27, 27, 27, 27] | min/median/max: (26, 26, 27)\nmodularity Q: 0.9793\n\n== G_all / LabelProp ==\ncommunities: 67\nsize stats (top5): [27, 27, 27, 27, 27] | min/median/max: (2, 26, 27)\nmodularity Q: 0.9567\n\n== G_close / Louvain ==\ncommunities: 50\nsize stats (top5): [27, 27, 27, 27, 27] | min/median/max: (26, 26, 27)\nmodularity Q: 0.9799\n\n== G_close / LabelProp ==\ncommunities: 296\nsize stats (top5): [17, 17, 14, 14, 12] | min/median/max: (2, 4, 17)\nmodularity Q: 0.7696\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n\ntrue = [family_id[n] for n in people]\n\nfor (Gname, alg), comms in parts.items():\n    pred_map = comm_map(comms)\n    pred = [pred_map[n] for n in people]\n    nmi = normalized_mutual_info_score(true, pred)\n    ari = adjusted_rand_score(true, pred)\n    print(f\"{Gname:7s} {alg:7s} | NMI={nmi:.4f} | ARI={ari:.4f} | #comms={len(comms)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T08:15:38.452309Z","iopub.execute_input":"2026-02-03T08:15:38.452783Z","iopub.status.idle":"2026-02-03T08:15:39.275719Z","shell.execute_reply.started":"2026-02-03T08:15:38.452743Z","shell.execute_reply":"2026-02-03T08:15:39.274889Z"}},"outputs":[{"name":"stdout","text":"G_all   louvain | NMI=1.0000 | ARI=1.0000 | #comms=50\nG_all   lpa     | NMI=0.9868 | ARI=0.9713 | #comms=67\nG_close louvain | NMI=1.0000 | ARI=1.0000 | #comms=50\nG_close lpa     | NMI=0.8380 | ARI=0.4256 | #comms=296\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def nuclear_coherence(comms):\n    cm = comm_map(comms)\n    ok = 0\n    total = 0\n    for (p1,p2), kids in couple_children.items():\n        members = set(kids) | {p1,p2}\n        total += 1\n        labs = {cm[m] for m in members if m in cm}\n        if len(labs) == 1:\n            ok += 1\n    return ok, total, ok/total if total else 0\n\nfor (Gname, alg), comms in parts.items():\n    ok,total,rate = nuclear_coherence(comms)\n    print(f\"{Gname:7s} {alg:7s} | nuclear families kept intact: {ok}/{total} ({rate:.3f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T08:15:39.276708Z","iopub.execute_input":"2026-02-03T08:15:39.277728Z","iopub.status.idle":"2026-02-03T08:15:39.289486Z","shell.execute_reply.started":"2026-02-03T08:15:39.277697Z","shell.execute_reply":"2026-02-03T08:15:39.288543Z"}},"outputs":[{"name":"stdout","text":"G_all   louvain | nuclear families kept intact: 445/445 (1.000)\nG_all   lpa     | nuclear families kept intact: 414/445 (0.930)\nG_close louvain | nuclear families kept intact: 445/445 (1.000)\nG_close lpa     | nuclear families kept intact: 247/445 (0.555)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\ndef gen_span_stats(comms):\n    spans = []\n    for c in comms:\n        g = [gen[n] for n in c]\n        spans.append(max(g) - min(g) + 1)\n    return pd.Series(spans)\n\nfor (Gname, alg), comms in parts.items():\n    s = gen_span_stats(comms)\n    print(f\"\\n{Gname} {alg} generation span:\")\n    print(s.describe())\n    print(\"span value counts (top):\")\n    print(s.value_counts().sort_index().head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T08:15:39.291314Z","iopub.execute_input":"2026-02-03T08:15:39.291999Z","iopub.status.idle":"2026-02-03T08:15:39.325586Z","shell.execute_reply.started":"2026-02-03T08:15:39.291951Z","shell.execute_reply":"2026-02-03T08:15:39.324787Z"}},"outputs":[{"name":"stdout","text":"\nG_all louvain generation span:\ncount    50.000000\nmean      5.580000\nstd       0.784805\nmin       4.000000\n25%       5.000000\n50%       6.000000\n75%       6.000000\nmax       7.000000\ndtype: float64\nspan value counts (top):\n4     4\n5    18\n6    23\n7     5\nName: count, dtype: int64\n\nG_all lpa generation span:\ncount    67.000000\nmean      4.970149\nstd       1.413894\nmin       2.000000\n25%       4.000000\n50%       5.000000\n75%       6.000000\nmax       7.000000\ndtype: float64\nspan value counts (top):\n2     8\n3     2\n4     8\n5    20\n6    24\n7     5\nName: count, dtype: int64\n\nG_close louvain generation span:\ncount    50.000000\nmean      5.580000\nstd       0.784805\nmin       4.000000\n25%       5.000000\n50%       6.000000\n75%       6.000000\nmax       7.000000\ndtype: float64\nspan value counts (top):\n4     4\n5    18\n6    23\n7     5\nName: count, dtype: int64\n\nG_close lpa generation span:\ncount    296.000000\nmean       3.875000\nstd        1.414663\nmin        1.000000\n25%        3.000000\n50%        4.000000\n75%        5.000000\nmax        7.000000\ndtype: float64\nspan value counts (top):\n1     1\n2    70\n3    50\n4    64\n5    71\n6    35\n7     5\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def participation_coeff(G, comms):\n    cm = comm_map(comms)\n    pc = {}\n    for n in G.nodes():\n        if G.degree(n, weight='weight') == 0:\n            pc[n] = 0.0\n            continue\n        k = defaultdict(float)\n        for nbr, attr in G[n].items():\n            w = attr.get('weight', 1.0)\n            k[cm[nbr]] += w\n        tot = sum(k.values())\n        pc[n] = 1.0 - sum((x/tot)**2 for x in k.values())\n    return pc\n\nfor (Gname, alg), comms in parts.items():\n    G = G_all if Gname=='G_all' else G_close\n    pc = participation_coeff(G, comms)\n    top = sorted(pc.items(), key=lambda x: x[1], reverse=True)[:10]\n    print(f\"\\nTop bridges by participation: {Gname} {alg}\")\n    print(top)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T08:15:39.326810Z","iopub.execute_input":"2026-02-03T08:15:39.327133Z","iopub.status.idle":"2026-02-03T08:15:39.491041Z","shell.execute_reply.started":"2026-02-03T08:15:39.327097Z","shell.execute_reply":"2026-02-03T08:15:39.490248Z"}},"outputs":[{"name":"stdout","text":"\nTop bridges by participation: G_all louvain\n[('adam1073', 0.0), ('adam125', 0.0), ('adam1281', 0.0), ('adam198', 0.0), ('adam306', 0.0), ('adam359', 0.0), ('adam426', 0.0), ('adam474', 0.0), ('adam627', 0.0), ('adam719', 0.0)]\n\nTop bridges by participation: G_all lpa\n[('adam892', 0.5), ('elias865', 0.5), ('emma951', 0.5), ('johanna688', 0.5), ('karin651', 0.5), ('katharina861', 0.5), ('larissa1020', 0.5), ('laura851', 0.5), ('nico888', 0.5), ('noah1194', 0.5)]\n\nTop bridges by participation: G_close louvain\n[('adam1073', 0.0), ('adam125', 0.0), ('adam1281', 0.0), ('adam198', 0.0), ('adam306', 0.0), ('adam359', 0.0), ('adam426', 0.0), ('adam474', 0.0), ('adam627', 0.0), ('adam719', 0.0)]\n\nTop bridges by participation: G_close lpa\n[('angelina978', 0.78125), ('marcel214', 0.7733333333333333), ('marie215', 0.7733333333333333), ('adrian213', 0.7681660899653979), ('lena1265', 0.7681660899653979), ('marcel27', 0.743801652892562), ('oliver165', 0.743801652892562), ('patrick1290', 0.743801652892562), ('philipp503', 0.743801652892562), ('sofia28', 0.743801652892562)]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from collections import deque\n\n# Precompute ancestor depths per node within each family (fast enough here)\nsubT = {i: T.subgraph(comp).copy() for i, comp in enumerate(comps)}\n\ndef anc_depth_map(sub, node):\n    d = {node: 0}\n    q = deque([node])\n    while q:\n        x = q.popleft()\n        for p in sub.predecessors(x):\n            if p not in d:\n                d[p] = d[x] + 1\n                q.append(p)\n    return d\n\nanc = {}\nfor i in range(len(comps)):\n    anc[i] = {n: anc_depth_map(subT[i], n) for n in subT[i].nodes()}\n\ndef relatedness(a, b):\n    if family_id[a] != family_id[b]:\n        return 0.0\n    i = family_id[a]\n    da = anc[i][a]; db = anc[i][b]\n    common = set(da) & set(db)\n    if not common:\n        return 0.0\n    smin = min(da[x] + db[x] for x in common)\n    cmin = [x for x in common if da[x] + db[x] == smin]\n    return len(cmin) * (0.5 ** smin)\n\n# Demo: sample 10 random pairs inside same family and print score + hop distance on backbone\nimport random\nrandom.seed(42)\n\npairs = []\nfam0 = list(comps[0])\nfor _ in range(10):\n    a,b = random.sample(fam0,2)\n    pairs.append((a,b, relatedness(a,b)))\n\npairs_sorted = sorted(pairs, key=lambda x: x[2], reverse=True)\nprint(\"Sample relatedness scores (same family):\")\nfor a,b,s in pairs_sorted:\n    print(a,b,\"score=\",s)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T08:15:39.492211Z","iopub.execute_input":"2026-02-03T08:15:39.492582Z","iopub.status.idle":"2026-02-03T08:15:39.522196Z","shell.execute_reply.started":"2026-02-03T08:15:39.492544Z","shell.execute_reply":"2026-02-03T08:15:39.521196Z"}},"outputs":[{"name":"stdout","text":"Sample relatedness scores (same family):\nmarko1057 hannah1068 score= 0.25\nlaura1075 vanessa1060 score= 0.25\nhannah1068 angelina1059 score= 0.125\ntobias1076 jan1062 score= 0.125\nmaria1077 nora1056 score= 0.0\nmoritz1061 isabella1065 score= 0.0\nisabella1065 nora1056 score= 0.0\nolivia1054 isabella1065 score= 0.0\nhelena1070 tobias1076 score= 0.0\nnina1063 moritz1061 score= 0.0\n","output_type":"stream"}],"execution_count":11}]}